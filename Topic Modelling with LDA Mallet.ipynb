{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aster\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'review_id', 'user_id', 'business_id', 'stars_x', 'date',\n",
       "       'text', 'useful', 'funny', 'cool', 'name', 'neighborhood', 'address',\n",
       "       'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars_y',\n",
       "       'review_count', 'is_open', 'categories', 'lang'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('restaurant_cleaned.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= gensim.corpora.Dictionary(docs)\n",
    "\n",
    "#convert docs to vec\n",
    "v = [d.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aster\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.027*\"tabl\" + 0.023*\"time\" + 0.021*\"order\" + 0.017*\"wait\" + 0.016*\"servic\" + 0.015*\"minut\" + 0.014*\"server\" + 0.014*\"busi\" + 0.013*\"back\" + 0.013*\"peopl\"')\n",
      "(1, '0.022*\"dish\" + 0.017*\"time\" + 0.016*\"love\" + 0.016*\"staff\" + 0.015*\"atmospher\" + 0.015*\"recommend\" + 0.014*\"drink\" + 0.013*\"experi\" + 0.013*\"japanes\" + 0.013*\"restaur\"')\n",
      "(2, '0.035*\"order\" + 0.017*\"restaur\" + 0.016*\"nice\" + 0.016*\"portion\" + 0.015*\"tast\" + 0.013*\"small\" + 0.013*\"menu\" + 0.013*\"3\" + 0.012*\"2\" + 0.011*\"servic\"')\n",
      "(3, '0.031*\"burger\" + 0.023*\"fri\" + 0.018*\"eat\" + 0.017*\"chees\" + 0.017*\"make\" + 0.016*\"time\" + 0.013*\"option\" + 0.011*\"thing\" + 0.011*\"menu\" + 0.010*\"review\"')\n",
      "(4, '0.059*\"sandwich\" + 0.047*\"smoke\" + 0.030*\"line\" + 0.024*\"montreal\" + 0.021*\"wait\" + 0.017*\"pickl\" + 0.016*\"schwartz\" + 0.015*\"worth\" + 0.013*\"visit\" + 0.012*\"long\"')\n",
      "(5, '0.037*\"fri\" + 0.026*\"pork\" + 0.022*\"mi\" + 0.019*\"beef\" + 0.018*\"banh\" + 0.016*\"delici\" + 0.015*\"kimchi\" + 0.014*\"belli\" + 0.012*\"bao\" + 0.011*\"love\"')\n",
      "(6, '0.016*\"poutin\" + 0.015*\"delici\" + 0.014*\"egg\" + 0.014*\"fresh\" + 0.012*\"made\" + 0.012*\"love\" + 0.011*\"spot\" + 0.011*\"brunch\" + 0.011*\"back\" + 0.009*\"amaz\"')\n",
      "(7, '0.029*\"ramen\" + 0.027*\"noodl\" + 0.025*\"price\" + 0.021*\"servic\" + 0.020*\"bun\" + 0.016*\"tast\" + 0.015*\"bar\" + 0.014*\"chicken\" + 0.014*\"pork\" + 0.013*\"disappoint\"')\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({'MALLET_HOME':r'D:/mallet-2.0.8/'})\n",
    "\n",
    "mallet_path = r'D:\\mallet-2.0.8\\bin\\mallet'\n",
    "\n",
    "ldamallet= gensim.models.wrappers.LdaMallet(mallet_path, corpus = v, num_topics = 8, id2word = d)\n",
    "\n",
    "vecTop= ldamallet.show_topics()\n",
    "for i in range(0, 8):\n",
    "    print(vecTop[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#Save a model to disk, or reload a pre-trained model\n",
    "\n",
    "joblib.dump(ldamallet, 'reviews_ldamallet.jl')\n",
    "\n",
    "# # then reload it with\n",
    "ldamallet_disk = joblib.load('reviews_ldamallet.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.027*\"tabl\" + 0.023*\"time\" + 0.021*\"order\" + 0.017*\"wait\" + 0.016*\"servic\" + 0.015*\"minut\" + 0.014*\"server\" + 0.014*\"busi\" + 0.013*\"back\" + 0.013*\"peopl\"')\n",
      "(1, '0.022*\"dish\" + 0.017*\"time\" + 0.016*\"love\" + 0.016*\"staff\" + 0.015*\"atmospher\" + 0.015*\"recommend\" + 0.014*\"drink\" + 0.013*\"experi\" + 0.013*\"japanes\" + 0.013*\"restaur\"')\n",
      "(2, '0.035*\"order\" + 0.017*\"restaur\" + 0.016*\"nice\" + 0.016*\"portion\" + 0.015*\"tast\" + 0.013*\"small\" + 0.013*\"menu\" + 0.013*\"3\" + 0.012*\"2\" + 0.011*\"servic\"')\n",
      "(3, '0.031*\"burger\" + 0.023*\"fri\" + 0.018*\"eat\" + 0.017*\"chees\" + 0.017*\"make\" + 0.016*\"time\" + 0.013*\"option\" + 0.011*\"thing\" + 0.011*\"menu\" + 0.010*\"review\"')\n",
      "(4, '0.059*\"sandwich\" + 0.047*\"smoke\" + 0.030*\"line\" + 0.024*\"montreal\" + 0.021*\"wait\" + 0.017*\"pickl\" + 0.016*\"schwartz\" + 0.015*\"worth\" + 0.013*\"visit\" + 0.012*\"long\"')\n",
      "(5, '0.037*\"fri\" + 0.026*\"pork\" + 0.022*\"mi\" + 0.019*\"beef\" + 0.018*\"banh\" + 0.016*\"delici\" + 0.015*\"kimchi\" + 0.014*\"belli\" + 0.012*\"bao\" + 0.011*\"love\"')\n",
      "(6, '0.016*\"poutin\" + 0.015*\"delici\" + 0.014*\"egg\" + 0.014*\"fresh\" + 0.012*\"made\" + 0.012*\"love\" + 0.011*\"spot\" + 0.011*\"brunch\" + 0.011*\"back\" + 0.009*\"amaz\"')\n",
      "(7, '0.029*\"ramen\" + 0.027*\"noodl\" + 0.025*\"price\" + 0.021*\"servic\" + 0.020*\"bun\" + 0.016*\"tast\" + 0.015*\"bar\" + 0.014*\"chicken\" + 0.014*\"pork\" + 0.013*\"disappoint\"')\n"
     ]
    }
   ],
   "source": [
    "vecTop= ldamallet_disk.show_topics()\n",
    "for i in range(0, 8):\n",
    "    print(vecTop[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the reviews data to the model, v is the reviews transformed to word vectors by doc2bow\n",
    "m = ldamallet[v[0:len(v)]]\n",
    "\n",
    "#assign topic to each review\n",
    "import operator \n",
    "topic = []\n",
    "for x in m:\n",
    "    #find the topic with the highest proportions\n",
    "    t = max(x, key = operator.itemgetter(1))\n",
    "    topic.append(t[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map topic names to the topic numbers\n",
    "topic_dict = {0:'Atmosphere', 1:'Food', 2:'Service',\n",
    "             3:'Food', 4:'Waiting time', 5:'Food',\n",
    "             6:'Food', 7:'Hospitality'}\n",
    "\n",
    "top_10k = top_10k.replace({'topic':topic_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10k.to_csv(\"top_10k_mallet.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
